{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../github/tips-triks/utils/text')\n",
    "import  txtfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name = re.sub(r'[^\\w]', ' ', name)\n",
    "    name = re.sub(r'[,:._\\-\\[\\]\\d]', ' ', name)\n",
    "    \n",
    "    result = ''\n",
    "    for word in nltk.word_tokenize(name.lower()):\n",
    "        if word == 'nan':\n",
    "            word = 'krvnan'\n",
    "\n",
    "        result += ' ' + word\n",
    "\n",
    "    return result.strip()\n",
    "\n",
    "def read_and_clean_data():\n",
    "    train = pd.read_parquet('data_fusion_train.parquet')[['category_id', 'item_name']]\n",
    "    train = train[train.category_id != -1].drop_duplicates('item_name')\n",
    "    train['item_name'] = train['item_name'].apply(clean_name)\n",
    "\n",
    "    train.replace('', np.nan, inplace=True)\n",
    "    train.dropna(subset = ['item_name'], inplace = True)\n",
    "\n",
    "    return train.sample(frac=1)\n",
    "\n",
    "def get_freq_nwords_on_category(train):\n",
    "    df = pd.DataFrame(txtfeat.get_texts(train.set_index('category_id'), 'item_name', unique = False, sort = True, reset_index = False))\n",
    "    df1 = df.groupby(df.index).apply(lambda c: c.groupby('item_name').apply(len).sort_values(ascending = False))\n",
    "    df1 = df1.reset_index()\n",
    "    df1.columns = ['category_id', 'item_name', 'words_count_in_category']\n",
    "\n",
    "    df2 = pd.DataFrame(df.reset_index().groupby('category_id').apply(len), columns = ['all_corpus_words']).reset_index()\n",
    "\n",
    "    df1 =  df1.merge(df2)\n",
    "    df1['freq_in_category'] = df1.words_count_in_category/df1.all_corpus_words\n",
    "    df_type = df1.groupby('category_id').apply(lambda g : g.freq_in_category.mean() < g.freq_in_category.std()).reset_index()\n",
    "    df_type.columns = ['category_id', 'word_type_in_category']\n",
    "    \n",
    "    df1 =  df1.merge(df_type)\n",
    "    df1 =  df1.merge(pd.Series(df1.groupby('item_name').apply(lambda g: g.freq_in_category.mean()), name = 'freq_in_corpus').reset_index())\n",
    "\n",
    "    return df1\n",
    "\n",
    "def split_data_on_uniq_and_mix(data, vocab_uniq_category_words):\n",
    "    freq_on_uniq_words = CountVectorizer(binary=True)\n",
    "    freq_on_uniq_words.fit(vocab_uniq_category_words.item_name)\n",
    "    data_transformed = pd.DataFrame(freq_on_uniq_words.transform(data.item_name).toarray(),\n",
    "                                    columns = freq_on_uniq_words.get_feature_names(), index = data.index)\n",
    "    data_on_uniq_indexes = data_transformed[(data_transformed.sum(axis = 1) > 0).values].index\n",
    "\n",
    "    data_mix  = data[data.index.isin(data_on_uniq_indexes) == False]\n",
    "    data_uniq = data[data.index.isin(data_on_uniq_indexes) == True]\n",
    "    \n",
    "    return data_mix, data_uniq\n",
    "\n",
    "def get_vocab_uniq_words(train):\n",
    "    words_in_categories_stat = get_freq_nwords_on_category(train)\n",
    "    vocab_uniq_category_words = words_in_categories_stat[words_in_categories_stat.freq_in_category == words_in_categories_stat.freq_in_corpus].reset_index(drop = True)\n",
    "    return vocab_uniq_category_words\n",
    "\n",
    "def train_model(x, y):\n",
    "    clf = LinearSVC(random_state = 42)\n",
    "    print(cross_val_score(clf, x, y, cv=3, scoring='f1_weighted'))\n",
    "    _ = clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "def write_submit_cl_map(freq_mix, clf_task1_mix):\n",
    "    !cd booster_submit;rm submit.zip freq_mix freq_uniq clf_task1_mix clf_task1_uniq script.py\n",
    "\n",
    "    pickle.dump(freq_mix, open('booster_submit/freq_mix', 'wb'))\n",
    "    pickle.dump(clf_task1_mix, open('booster_submit/clf_task1_mix', 'wb'))\n",
    "    \n",
    "    !cd booster_submit;cp ../script_cl_map.py script.py\n",
    "        \n",
    "def write_submit_cl_cl(freq_mix, freq_uniq, clf_task1_mix, clf_task1_uniq):\n",
    "    !cd booster_submit;rm submit.zip freq_mix freq_uniq clf_task1_mix clf_task1_uniq script.py\n",
    "\n",
    "    pickle.dump(freq_mix, open('booster_submit/freq_mix', 'wb'))\n",
    "    pickle.dump(freq_uniq, open('booster_submit/freq_uniq', 'wb'))\n",
    "    pickle.dump(clf_task1_mix, open('booster_submit/clf_task1_mix', 'wb'))\n",
    "    pickle.dump(clf_task1_uniq, open('booster_submit/clf_task1_uniq', 'wb'))\n",
    "\n",
    "    !cd booster_submit;cp ../script_cl_cl.py script.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_and_clean_data()\n",
    "vocab_uniq_category_words = get_vocab_uniq_words(train)\n",
    "train_mix, train_uniq = split_data_on_uniq_and_mix(train, vocab_uniq_category_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_uniq_category_words.set_index('item_name', drop = True)[['category_id']].to_csv('uniq_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_as_cl_map = True\n",
    "\n",
    "stop = stopwords.words('russian')\n",
    "freq_mix = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_mix = freq_mix.fit_transform(train_mix['item_name'])\n",
    "clf_mix = train_model(X_train_mix, train_mix.category_id)\n",
    "\n",
    "if submit_as_cl_map == True:\n",
    "    write_submit_cl_map(freq_mix, clf_mix)\n",
    "else:\n",
    "    freq_uniq = CountVectorizer(binary=True)\n",
    "    X_train_uniq = freq_uniq.fit_transform(train_uniq['item_name'])\n",
    "    clf_uniq = train_model(X_train_uniq, train_uniq.category_id)\n",
    "    write_submit_cl_cl(freq_mix, freq_uniq, clf_mix, clf_uniq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
